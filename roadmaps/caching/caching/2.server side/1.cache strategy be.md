Tentu, Bos! Berikut ringkasan artikel **"Cache Strategy in Backend"** oleh Genchi Lu, yang membahas strategi caching dalam pengembangan backend:

---

## 🧠 1. **Berapa Banyak Data yang Harus Disimpan di Cache?**

Sebelum menerapkan arsitektur cache, penting untuk memperkirakan kebutuhan memori cache. Penulis menyarankan menggunakan **aturan 80/20**, di mana **20% objek digunakan 80% dari waktu**. Dengan demikian, menyimpan 20% data yang paling sering diakses dapat meningkatkan kinerja secara signifikan.

**Contoh:**

* Jumlah pengguna aktif harian: 10 juta
* Ukuran metadata per pengguna: 500 KB
* Data yang perlu dicache: 500 KB × 10 juta × 0,2 = **100 GB**

Dengan kapasitas memori VM cloud saat ini sekitar 512 GB, satu VM dapat menampung cache tersebut. Namun, dalam kasus ekstrem, mungkin perlu menyimpan semua data dalam memori untuk mengurangi latensi, tergantung pada kebutuhan sistem.

---

## 🗃️ 2. **Cluster Cache**

Jika cache tidak muat dalam satu VM, solusi selanjutnya adalah menggunakan **cluster cache**. Umumnya, digunakan fungsi hash untuk menentukan node cache yang sesuai, misalnya dengan menggunakan ID permintaan sebagai kunci dan fungsi mod sebagai hash.

Namun, pendekatan ini memiliki kelemahan: menambahkan node baru dapat menyebabkan redistribusi data yang signifikan, mengakibatkan migrasi data yang besar. Untuk mengatasi ini, penulis menyarankan penggunaan **consistent hashing**, yang meminimalkan jumlah data yang perlu dipindahkan saat ukuran cluster berubah.

---

## 🔁 3. **Kebijakan Penggantian (Replacement Policy)**

Karena tidak semua data disimpan dalam cache, diperlukan kebijakan untuk menentukan data mana yang harus dikeluarkan saat cache penuh. Beberapa kebijakan umum:

* **FIFO (First In First Out):** Data yang disimpan lebih awal dikeluarkan lebih dulu.
* **LFU (Least Frequently Used):** Data yang paling jarang digunakan dikeluarkan lebih dulu.
* **LRU (Least Recently Used):** Data yang paling lama tidak digunakan dikeluarkan lebih dulu.

Penulis menyebutkan bahwa **LRU** adalah yang paling umum digunakan.

---

## ✍️ 4. **Kebijakan Pembaruan (Update Policy)**

Tiga pendekatan utama untuk memperbarui cache:

1. **Write-through:** Memperbarui database dan cache secara bersamaan. Menjamin konsistensi kuat antara cache dan database, tetapi meningkatkan beban saat menulis data.
2. **Write-around:** Hanya memperbarui database dan menginvalkan data cache saat menulis. Cache diperbarui saat data dibaca. Risiko awal cache miss lebih tinggi.
3. **Write-back:** Hanya memperbarui cache saat menulis, dan menulis kembali ke database setelah interval waktu tertentu. Meningkatkan latensi dan throughput, tetapi berisiko kehilangan data jika sistem crash sebelum penulisan ke database.

---

## ✅ Kesimpulan

Caching adalah komponen penting dalam arsitektur backend. Artikel ini membahas:

* Estimasi kebutuhan memori cache menggunakan aturan 80/20.
* Penggunaan cluster cache dan pentingnya consistent hashing.
* Kebijakan penggantian data dalam cache.
* Strategi pembaruan cache untuk menjaga konsistensi dan kinerja.

Dengan mempertimbangkan aspek-aspek ini, kita dapat membangun arsitektur cache yang lebih tangguh, stabil, efisien, dan sesuai dengan kebutuhan sistem.

---

Jika Bos ingin mendalami topik tertentu atau memiliki pertanyaan lebih lanjut, silakan beri tahu saya!
